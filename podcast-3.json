{"podcast_details": {"podcast_title": "DataFramed", "episode_title": "#150 Unlocking the Power of Data Science in the Cloud", "episode_image": "https://artwork.captivate.fm/4700b4b7-f386-4200-9a46-640458f2dcbd/5cfec01b44f3e29fae1fb88ade93fc4aecd05b192fbfbc2c2f1daa412b7c192.jpg", "episode_transcript": " Open up your thinking in your mind, right? Because now that you're in this new world, the barriers in my experience become lower. So if you have a barrier, you've got a roadblock, if you're not meeting the price that you need, the performance that you need, don't stop with, it's okay, good enough is good enough. I'd say open up your mind and say, there's a better way. Welcome to Data Framed. This is Richie. If you're a data scientist, the infrastructure of your analyses may not be something you regularly pay attention to. But where your company keeps your data and your analysis tools is going to have an impact on your ability to work efficiently. So it's worth having some awareness of best practices. In particular, one of the biggest productivity boosts you can get is from moving analytics from local machines and on-premise servers to cloud platforms. The catch is that migrating your data infrastructure is a big project that involves a lot of people and moving parts. Since so much of your business will be impacted, it's something you need to plan carefully to get it right. Today I have two experts from high-performance cloud database company Exosol to help me think about making this transition. John Kniereman is the General Manager for North America and Solongo Guzman is the Global Head of Customer Success. Both of them have extensive experience in helping organizations make the transition to doing analytics in the cloud. I'm looking forward to hearing their opinions on what to do and what not to do while running a cloud transition project. Let's dive in and hear their advice. Hi there, John and Solongo. Great to have you on the show. Hi, Richie. I'm Richie, a cloud analyst. Thanks for having us. I'd like to kick off with a little bit of motivation. Can you just tell me why you might want to move your analytics to the cloud? What's the pitch? Again, thank you for having us, Richie. This is a really exciting discussion for me and I'm really looking forward to our time together here. You move your analytics to the cloud primarily for the flexibility the cloud allows. In the prior model, in the on-prem model, a lot of times you don't have the flexibility you need from a data analyst perspective, from a data science perspective. You're subject to creating an on-prem infrastructure that requires regular updates internally. There's process. You don't get the flexibility that you need and sometimes the cost is not what you need as well. Some organizations have decided that they want to get out of the business of managing a platform. They want to be more strategic in the way they interact with technology and choose technology. At a high level, that's really the high-level pitch for moving analytics to the cloud. Since there's a lot of bits of analytics stacked, there's a lot of things you might want to move to the cloud. Can you just talk us through about what are all the different parts that you might want to move to the cloud? Absolutely. In terms of layers, you can think about your analytics layer as the storage layer starting out and then there's the integration ingestion layer. There's the processing layer and your analysis layer. The easiest way to approach this is starting with your storage layer. Cold object store is relatively cheap in the cloud. That can be your Amazon S3. That can be your Azure Blob or Google Cloud Storage. That would be a great place to start. Then you connect that with your enterprise data analytics warehouse or database. Then you have the composable services that you can start playing around with. Okay, so you're suggesting you just start with a load of files lying about, shift them to the cloud first, and then worry about the analytics later. That's interesting. Okay, so I guess before we decide that moving everything to the cloud is a brilliant idea, what are the alternatives to this? Yes, so it was basically an alternative to have either a full on-prem infrastructure, a hybrid infrastructure, part on-prem, part in the cloud, and then all in cloud. Those are really the three different scenarios. The benefit of all in cloud, as you look at what I said earlier around the flexibility and the ability to design your architecture in the way you want to design it, it's really optimal. I sat down with a chief data officer a few months ago, and she basically told me, she said, I want my architecture to be like a Lego set. I said, what does that mean? She said, I basically want it to have those nice holes and fittings that fit together nicely, then I can design it the way I want to design it. That's really what a lot of organizations are looking for. So the cloud really enables quite a bit of that. Some organizations, if you go to the other side, have a need to be fully on-prem, whether it's regulatory concerns around security or having the ability to control their whole destiny end to end. Some organizations are doing that today. Then I actually see a growing number of organizations in the middle with a hype, some part on-prem, part in the cloud, and they're making decisions for those environments and deployments based on what they're trying to achieve. If you are going to push things into the cloud, it seems like maybe the reason you talk about like to keep things on-premises is going to be worries about privacy and security and things like that. So how do you address those if you're going to move to the cloud? So at a high level, when you move into particularly a public cloud provider, their whole business is centered around security, particularly the three major cloud providers. If they don't have tight security for both public and private sector, they really won't have a business. So those organizations have really excruciatingly tight security that they follow. And then all of the technologies that fit within that environment are naturally as secure. So from a security perspective, when you're all in cloud, you're doing the analysis on the public cloud provider side. And then fully on-prem, you have to do all that yourself. You do all that vetting yourself and work with either a software provider and or your security team within your organization to figure that out. Okay. So it sounds like a lot of this is about how much do you want to do yourself versus how much do you want to outsource to other platforms and tools? Correct. Okay. So are there any economic factors that drive this sort of migration of analytics to the cloud? Cost savings. I think it boils down to how much upfront expenditures you're willing to kind of forego. The process of provisioning a physical infrastructure where we've seen it can be a very long process in a large enterprise. It starts with infrastructure planning, architecture design that can take anywhere between three to four months. There's an internal certification process. Typically, we see this in financial services. So there's the infrared design pattern documentation, and that can take anywhere between five to six months. And then there's the actual physical hardware delivery and the installation of the different environments, dev, test, prod, and the data centers. So by the time the business has access to the environment, it can take as long as 12 months. So with the cloud, you're foregoing that. And with the pay as you go model, you pay for only the resources you consume. So that eliminates the need for you to provision the resources upfront. And it's also increasing scalability and agility. So what that means is you're able to respond effectively to fluctuations of workload. So you're able to reduce the need for over-provisioning, and you're able to scale much faster. There's increased operational efficiency. So there's overall reduced maintenance and downtime. The economics are incredibly attractive for going to the cloud. I think saving money and doing things faster, that's a pretty strong argument for making the move. So what's the initial trigger in general? So what's the point where companies realize, OK, we need to start doing this migration? Yeah, I would say there are several triggers. First and foremost, it's are you able to meet your business needs and objectives in the way that you've designed what you've designed, right? So you think about the data scientists and the data analysts. Are they able to be the most efficient in their role to be able to succeed fast, fail fast, be able to get the performance they need, to be able to access the data they need across the organization? If that is a concern, that would be a trigger to look at what type of deployment model issue. Is it a process issue? It's not always where the data sits or how you deploy it. Sometimes it's just a matter of process and how the organization is structured by who has access to data and how they access. I would also say that, to Salongo's point, costs could be a driver. When you look at the cost and look at sometimes on-prem, you have to design for worst case scenario. So you're designing this unilateral architecture that is worst case scenario versus being able to, to her point, be able to use a consumption-based model just exactly what you need. The third one is probably the most obvious. Sometimes there's a mandate from a C-level executive that says, we shall go to the cloud, and that gets everybody rallied in that direction. I certainly think those economic drivers are pretty relevant at the moment. There's a lot of companies trying to cut some costs. But on that last point, I have a feeling a lot of our listeners might be the people who are having to implement this sort of stuff. Suppose your CTO comes to you and says, okay, we need to move all our analytics to the cloud. Where do you start? Where we see this is really use case oriented. So the market has changed quite a bit. Generally, we saw a decade ago the CTO, CIO-driven top-down decision-making, but now you see this mass consumerization of data and analytics. So what that means is the business and the users are really creating these use cases. It's really use case oriented. So if they have a need to go to the cloud, they need to do it quickly. They want to modernize their solution as opposed to doing a more lift and shift. Because if you have silos, if you have issues on premise, why would you want to migrate that onto the cloud? So you want to take a much more holistic approach and starting out with maybe the highest pain point and say, what is the use case that needs to go to the cloud and start with that? Then maybe adapting a proof of concept and starting there because the cultural aspect might be one of the biggest barriers of this migration. That's really interesting, the idea that I guess it's true in every company. They're like, oh, I hate the structure of our data. We've got data silos everywhere. It's probably like one magic company out there to have that problem. But the idea of just changing your infrastructure gives you the opportunity to just rebuild things from scratch and maybe do things better. All right. So you mentioned starting with high impact projects. So I'm wondering what the trade-off is here between starting with high impact projects versus starting with low risk projects. What's the thinking behind how you decide what to move first? I would say organization is different. When you look at what I mentioned earlier around the projects that are creating the most pain, I think those are probably the most obvious. So the situations where you're physically hindering your role as an analyst or data scientist, those would be the potential ones to Slamo's point that you may move right now because there's not a lot to lose in that. The risk is very low on that one. There's probably only upside to that situation. There's maybe other ones that if you can use the analogy, it isn't broken, don't fix it. Maybe those you would look at and put those further on the roadmap. So being able to look at the ones that are creating the most pain, the ones that are running okay, and then systematically migrating, when it gets to the ones that are running okay, you might even make the decision to do those as well because there's an economic advantage to having everything in a cohesive environment. I think hopefully people are sold with the idea that this is a good idea to move things. Who needs to be involved in this process? It's everybody, especially now when Gartner has done a phenomenal job with their data analytics maturity model and the frameworks. So the simple answer is the business and tech teams both need to be involved as well as the executive decisioning. And a cloud migration is a strategic decision. So you need to have obviously the executive buy-in. But in order to move the organization up the maturity model, you need the entire organization on board. That means the business teams, the tech teams and the leadership. Okay. So that's a lot of people. So by the time you've got the users and anyone who's involved in data and anyone who's involved in IT and leadership, how do you manage all these different teams working together? I imagine they're going to have different viewpoints on what to do. The way you manage it is really bringing the teams closer together. So in the traditional model, there is an IT perspective on the types of technologies that would solve a business challenge. So there's already that, should have been that natural relationship with the business and IT. But at the end of the day, the IT group would normally say, I can or can't do this depending on the technology and the stack that I'm aware of. In this other model, it actually, with more flexibility, comes more responsibility for the data analysts and data scientists because now they're in a position where the operational side is mostly covered, right? Because you're in an environment that, as we talked about earlier, is secure and works well together and is a marketplace of tools and solutions. So at that point, the data analysts and the data scientists become more powerful to be able to make those types of decisions. But the IT group still being informed is extremely key, right? So any organization where there's decisions happening in silos, and I've seen both, where IT is designing and building, they will come. And I've seen the business side making new, lateral decisions. If the business side is making new, lateral decisions, the risk is that there's a lack of governance and potentially a high cost, right? Because they're deploying at will and cycling their credit card and things can get out of control in all different areas. So there's still a requirement to have, to some point, people very tightly engaged across the organization. And then from an executive perspective, that they're aware of the opportunities and the risks and they have full support for the organization as well. And do you have any sort of tips on it? It seems like communication is sort of the big key here. So do you have any tips on like how to communicate across teams or how to manage these big processes? So Center of Excellence have worked really well, especially in big, complex organizations, bringing a committee together and having various members from the stakeholder group work well. But also, we're seeing it happen at a grassroots level. For example, at a big customer, we have advanced analytical capability now in the cloud. And now the users have never had this kind of access before. So now the question has turned into who has this data and when can I use it? And by default, that process has allowed closer collaboration of the different teams. That sounds pretty cool. And so maybe I'd like to hear a bit more about some of these success stories that you've had with your customers. So can you tell me an example of when a customer has been through this migration process and then they've had a big win from it? We had a large healthcare company that we work with, a US-based healthcare company, who made the decision to move to the cloud. Their decision was based on the fact that they wanted more flexibility, they wanted more agility, and they had a theory there was cost savings. So they ended up taking their current on-prem data, moving it into Object Store and the cloud provider that they were using. And that created a layer by which they can then make decisions to Lego analogy, how they plug the Legos in, the engines in to optimize that stack. And I'd say it's still a journey. What I applaud them for is they've been flexible along the journey. And that's one thing I'll stress is that the first step of the journey is critical to get the foundation built, but then you need to be flexible as you move through the journey and the cloud allows that flexibility. So they've taken a constant look at what engine's best for what job, what types of AI and ML tools are best for the teams. And it's been a very collaborative group. And we've been honored to be able to work with them too around some things around performance and some of the things that we provide. But it's just been a very, to applaud them again, they've been very flexible along the way and along the path. And back to your question about organizational, they've created a structure by which they have a center of excellence. They have regular meetings and interactions across the business and the IT groups, but then also with executives and they were in very cohesive unit. So it sounds like the big win for them has just been increased access to data and maybe are there any productivity benefits that go along with that? Yeah. So when they started this journey, the data analysts and data scientists were complaining because sometimes they could only run three or four questions of their data in a day, right? So one to two hour queries, things are just getting out of control. They go grab a cup of coffee. And by the time they came back, the query is maybe still running. They were ineffective and efficient because they couldn't succeed or fail fast enough to be productive within their organization. So when they moved into this cloud environment, they were able to select the right tools to be able to optimize. And now the data analysts and data scientists are far more efficient and being able to ask four more questions of data for a lower cost to be able to leverage those tools in the consumption based approach. And oh, so you mentioned this was like a healthcare provider. And I have to say like a data camp because we're tech startup, like we're a bit of course, like you do everything in the cloud. But I guess it sounds like a lot of the sort of benefit from this migration, it's going to be older companies and perhaps larger organizations. And would you say that's an accurate description of your customer base? Like who cares about this the most? No, I would say I would say it's actually particularly interesting for mid-tier companies because mid-tier companies don't necessarily have the massive amount of operational resources to support in the way that they need to support. This particular healthcare company was a large one that decided we don't want to be in the business of doing this. Even though we could, we don't want to be in the business of managing an operational platform. But for mid-tier organizations, we met with one last week where we had one guy who was basically running the whole shop and he was a solo guy running the whole shop. And so in that situation, cloud makes a ton of sense because you're able to leverage all of the operational support and the whole marketplace of tools and solutions you get when you can't necessarily afford to hire a whole team. In a lot of Fortune 100 companies and the power of going back to the business users, so instead of relying on IT, we have teams and two of the large telcos, they run their own infrastructure. So they own it, they run it, and a lot of the operational overhead is outsourced so they can be freed up to do more strategic work. With a large cost project like this from migration to cloud, you're going to want to see some kind of returns and you want to know how to measure those. So can you just talk about what's the measurement for the success of this? Absolutely. I think the first and foremost is why did you set out to do the project from the get-go? Was it cost savings? Was it scalability? Was it access for compute resources? I think that's the initial UAT, if you will. But the ultimate success is what we're seeing with our customers is data availability and accessibility. So when you have a single source of truth and improved governance, improved security, there is sort of a data flywheel happening where more users having access to the right data that they need at the time that they need it. Now the business is able to effectively harness more value out of their data. So it's going back to climbing up the maturity model and using data as a strategic driver for the business. Okay. So you really have to define some goals then upfront before you actually embark on this if you want to be able to accurately measure how well you're doing at the end of it. That makes a lot of sense. On the flip side, are there any things that can go wrong? What do you see are the most common problems? Yeah, I'd say that what can go wrong is maybe the first one we said could go right. It's when you don't go in eyes wide open, when you haven't done your due diligence to map out what you believe the business opportunities are, where the gaps are, how you can optimize for cost, how you can optimize for performance. Some people go in with blinders on to think that there's a utopia and they come to find out that their lack of planning means they're in a worse place than when they started. So I would stress that doing proper planning, making sure that you understand what the gaps are, what the tradeoffs are, and make the right decision for your business. And every business will be different. Some will be full all in cloud, some will be full on-prem, some will be a hybrid depending on your model and the market you're in and all that. So I would say that planning is extremely important and being realistic about when you're going to have those quick wins and where you're going to build the foundation is also important. You can always disappoint people when planning is a thing that you really need to do. It does sound to be important for someone to want to dive right in. You've got to be patient. So yeah. All right. So planning seems to be a very important thing. Having some goals seems to be an important thing. Are there any other tips you have for making sure that a migration project is a success? Yeah. I think it's arming yourself with as much knowledge. I think now that the responsibility shifts back to the users, you really have to know a lot about your cloud platform of choice. You got to know how the tools and the interoperability works because going back to the risks, you can never eliminate the human error. Cloud might be one of the safest places because of the robustness in security features, the data encryption at rest, in transit, but there are incidences of not provisioning things properly. So just knowing as much of this incredibly powerful capability will make sure that it'll be the best way to mitigate any risks. Yeah. I would also add that it's important to design that center of excellence we talked about earlier that is an educational center of excellence. Where I see some organizations struggling as well is fitting a square peg into a round hole from the tool perspective because some tools are designed for performance. Some are designed for ultra flexibility. Some are designed for just low cost. So if you use the tools in the way that they're not designed, you could escalate your costs and then hurt your ability to get performance and the data that you need. And then being able to design that data in a foundational way to be able to access the data you need across the organization. Not putting silos, not locking the data down for users is important in creating that center of excellence and having a shared network where people can share, hey, I used this tool for this and that you've worked well and be able to share among the company and organization is best practice. So you mentioned this term center of excellence a few times. So I'm curious as to what this involves. Is this like a dedicated team who just dedicated this one project or what's the deal here? It's all of it. So it's a team, it's a process, it's a mechanism in place where it allows you to make this incredibly otherwise complex project happen. So we're seeing cloud center of excellences. We have our own database center of excellence in certain customer sites where it allows people from other parts of the business and department to come together and share knowledge on an ongoing basis. So there's transparency. When there's transparency, there's better control. Okay. That sounds like a useful thing. Just having everything together in one place just so you can make sure that. I presume it makes communication easier if everyone's not to spread out around the globe and in different teams with different needs. All right. So we talked a lot about the sort of the general migration process. Maybe let's focus on databases since of course Exisol, you're primarily a database company. I think that's a fair characterization. So I guess the big names in cloud databases, it's like things like BigQuery and Redshift and Snowflake. So how does Exisol compare to those companies or those platforms? Yes, I'll start with the business challenge again we discussed earlier. So there's three different balancing acts if you can think of it that way is the ability to have choice within the database you select, the ability to optimize for cost and the ability to optimize for performance. So those are the three balancing metrics that you see with databases. We call ourselves a no compromise solution. So we're able to properly balance that. We've got a very strong foundation around an MPP-based architecture that can scale concurrent users and scale data seamlessly. But then we have the end memory technology that helps it operate very efficiently and very, very rapid, particularly at the BI layer, right? When you need to have second, sub-second type response times within queries. And then we have some things that virtualize. So we have in our database the ability to reach into different data sources natively structured and unstructured to be able to pull that data in so that the data analysts and data scientists don't have to worry about different systems and bringing systems together and moving data around. You can natively pull that in. And then we have things that are just native within our solution that make it easy to efficiently manage. It automatically creates the primary index and those sorts of things. So we're excited to be able to offer the market a no compromise solution when you look at those balancing metrics. So it sounds like high performance was a big part of your pitch there. You mentioned like the sub-second query times and things. Is it just about chasing faster query execution or are there other parts to improving the performance of people working with data? At the mechanical level, it's two things, Viji. It's faster ingestion and faster query times. But going back to what we said, we really focused on use cases and outcomes. So faster queries and faster ingestion, a lot of things for our customers. So typically when we're working with large enterprises, they're coming to us with specific purpose and specific outcome they want to achieve. So they want to increase revenue through strategic pricing and customer acquisition, or they want to reduce costs through reducing operational expenses or reducing risk and meeting compliance. So we are really focused on delivering what that use case requires. So it's much, much more encompassed and wrapped around faster ingestion and faster query times. So I quite like this idea of focusing on the use case and just getting beyond. You crunched SQL really quickly. Can you maybe give an example of one of these use cases where you've had to tailor what the database is doing to meet that need? Yeah, absolutely. We have a Telco customer that has a really cool use case. They're doing network optimization. So what they do is they have different data analysts and modeling teams. They generate models that make recommendations to improve 5G configuration plans and designs. And that also includes infrastructure acquisitions, which can be really expensive for Telco. So they're able to predict using models what type of investments would yield the highest ROI and what type of specific configurations, cell tower configurations. And they're able to track the progress of that using third party external crowdsourced data. So it's a full circle of not just providing the recommendations, but also seeing the progress and tracking the progress so they can improve their models and continue being that vital part of business decision making. That's actually a really interesting use case because it sounds like if they're using external data sources, you've got a data engineering component for bringing everything into the database. And then it's also about optimization or maybe machine learning on the other end of it as well, like some fairly sophisticated analytics. So how does the database fit into that kind of broader technology pipeline then? When you look at the pipeline, right, so you have the ingesting of data. The database is really the horsepower of the processing part of it. So whether you're running an AI ML model, whether you're running a report and a BI tool or solution, the horsepower usually comes from the database itself, right? So the database really offers it to make or break in a lot of cases to be able to offer the performance that you need across the infrastructure. Now it won't minimize other things like being able to properly prepare your data. And sometimes the ingest process is broken. So it's not just the database is the magic silver bullet. It never is, right? It's the end-to-end process. But the database is sometimes a key bottleneck for organizations if it's not utilized correctly and you're utilizing the right technology again for the right job. That's a really good answer, John. So we typically see three deployment patterns. So there are three main use cases that a data consumer can get to the database. So you have the traditional data engineers and DBAs using SQL and accessing the database like ExaSol, or you have the data analysts going through a BI reporting tool like Tableau or Power BI. And then you have the data scientists going through a data robot or SageMaker to access the database. But nonetheless, it is the compute engine. It's the heart of the operation. So when you have BI users complain how slow the dashboard is, it's actually the underlying database. So a lot of the credit goes to the front end. But what's actually happening is what's underneath the hood. Okay, yes, certainly. I've seen that where you've got a really clunky dashboard. I'm not sure what's going on there. Maybe it's the processing upstream from the dashboard that's actually the problem. So John, you mentioned bottlenecks. I'm curious to hear about, are there any more examples of analytic problems where it really benefits from that more powerful database engine in the middle? Yeah, so pretty much any industry that needs to make decisions in a quick enough period of time to actually affect, make or save money are critical. And I'll use a couple of examples. One's from retail, right? So you have a call center. You've got people that are taking calls. And a lot of call centers are selling centers in some cases, right? Where they're able to not just support the customer, but also to sell or upsell the customer. So in those types of situations, we work with a retailer around being able to do that in real time. So that's the person is sitting there with the individual on the other side of the line. They're running not just analytics, they're running predictive analytics. So to Salonga's point, they've gone up a maturity curve where they're saying, this person's calling, this is what we, based on all of the people encroaching in real time and the market and today and whether it's a holiday or not, they're able to make a predictive theory about what you should be discussing and presenting to that customer, right? So it's ultra critical that you've got an engine, a database that's able to do that. Another example is we're working with a high tech company around sustainability. So basically for all of their physical locations, they're attaching Exosol to be able to monitor energy consumption and usage in near real time to be able to make those adjustments. And again, it's not just descriptive, it's predictive analytics to be able to predict based on these types of energy consumption behaviors, we're going to go and adjust and optimize for sustainability. That's actually pretty cool because I guess when I think of databases, I'm thinking of like just doing really simple business analytics, crunching numbers. And once you start getting to like doing predictions, a bit of machine learning, then that's where you break out Python or R. But actually, the database part of that is from what you're saying, it sounds like this is still really important because you've got to get the numbers processed in the first place before you even start trying to do any of that. Okay, cool. I guess for people getting started with this, there's going to be a lot of organizations who are just trying to figure out cloud migration now. And so you mentioned having greater access to data was one of the big benefits, I think, for your healthcare example. In general, how do you think about data governance more generally at Exosol? I think by the process of migrating your analytics to the cloud, you have better metadata management, better cataloging, you're improving governance. We have seen that with a large customer where it's been traditionally on-premise and they had siloed datasets in their own business units. So there was a dispute on who had the source of truth. So by effectively having, they have a data lake now on Exosol in AWS, so it's a single source of truth. The governance has just improved and the business has access to already cleansed, wrangled data that the data scientists and modelers just can run with it. So they've seen improved governance, they've seen improved security by having a central repository. So I'd like to talk a little bit about skills. And does moving your analytics stack, like if you put it in the cloud, does that change the skills that your data analysts and your data scientists need? I'd say absolutely. That's a point I made earlier. With much flexibility comes responsibility, particularly for the analysts, data scientists, the business user, as we call them, to be able to be more in tune with not the depths of a technology, but how a technology functions and how it should be used. Because essentially now that it's on their shoulders, in a lot of cases, to make that selection, to pick the right tool for the right job, to not fit that square peg in that round hole. So they need to be more in tune with the types of technologies. Again, not the full architecture understanding, but enough to know when to deploy which, again, Lego on top of that Lego set for the particular thing that they're trying to achieve. I kind of like that. It's like, I don't need to understand the architecture. I just want to play with Lego all day. I have three young boys at home, so it resonates with me. I step on them on a daily basis, unfortunately, but it resonates with me. Nice. Okay. And so if you work on problems where you do need high performance, you mentioned some examples of working in retail, you need to get the answer in almost real time. So if you do have that need for really fast analytics, what sort of skills do you need to get there? Again, it boils down to the database, Ritchie, because the front end tool is only as powerful as the underlying database. So we see very common in the market. A Tableau is, for example, a popular dashboarding analytics BI tool. And you're able to do only subsets and extracts versus with Exasol, you're running analytics on a live data set through a live connection. So that really empowers the data scientists and analysts to do more analytics, richer analytics on bigger data sets and fresher data sets. So really, when you're playing around with powerful engine, powerful tools, especially in the cloud, when you have plethora of microservices, you have to know how these tools work together and really understand the power of this. Because the flip side of going with the KZGo model is if you don't know how to properly use it, the cost overrun can really be a surprise and you don't want to get that surprise bill at the end of the month. So you have to know how to provision them, you have to know how the tools work together. I was chatting to a data engineer recently and he was just like, oh, no, I left this database running for 10 days and didn't really remember it. And he said, yeah, he just got the bill for that. So certainly remember to turn off services you aren't using very good cloud advice. So I think to summarize your point that you were basically saying that if you want high performance stuff, you just need to buy the right tools first that are going to deliver that performance and then learn how to use those tools properly. And that seems to be the order rather than think about skills first, and then figure out tools after you've got those skills. Does that make sense? Is that what you're saying? It does. And I would also add that having the ability to work with IT is important as well. So having that sort of people interactions, being able to work well together with the team is important because it's again, the tool doesn't solve everything. It's the whole process end to end. For those data scientists, data analysts that have regularly scheduled interactions with IT and view them as a business partner, those are the ones that are most successful. And I think one thing that's sort of come a few times here is that you need to know a little bit about what the database is doing, what all the other tools are doing, even as a data analyst or data scientist where you're actually using these things. So are there any particular things that you think people need to know about the underlying tools and infrastructure? Yeah, I would say that some technologies as a data analyst, data scientist, you can hit select star and it's not going to crash the database. Others, it will basically totally crash and you'll be in a bad state. And so understanding enough about the types of ways that you would interact with the tool, the things that are okay, the things that are not okay and understanding those boundaries. Some tools have some databases have good workload management capabilities to be able to have one data analyst and a prioritization because they're running something critical for the CFO and the others are going to take in more priority that some tools have that some don't. So being able to understand that well enough to be able to go back to the IT group again and say, hey, I really need priority this week because I'm running this particular thing. And that's really important. And just to wrap up, do either of you have any final advice for organizations wanting to migrate through analytics stack to the cloud? I'd say start with a POC and really look at what is highest pain point, what's the most critical and start small and take a graduated approach and start with just the storage layer and play around with the microservices and see where it goes. And it's also important to focus on the quick wins while building up that long-term strategy. Oh, yeah. Proof of concept and getting a quick win seems very useful, especially if you've got impatient managers wanting to see results. And John, how about yourself? Any last advice? I agree with everything Salonga said. I would also say open up your thinking in your mind, right? Because now that you're in this new world, the barriers in my experience become lower. So if you have a barrier, you've got a roadblock, if you're not meeting the price that you need, the performance that you need, don't stop with it's OK, good enough is good enough. I'd say open up your mind and say there's a better way. There's a lot of tools out there. There's a lot of things we can do. And it's really exciting when organizations open up their thinking and say we can achieve what we need to achieve. Fantastic. And with that, thank you, Salonga. Thank you, John. It's been great having you on the show. Thank you, Richie. Thanks for having us. Thanks, Richie. It's been great. Thanks for having me."}, "podcast_summary": "In this podcast episode, the host explores the benefits and challenges of moving analytics to the cloud. He interviews experts from ExaSol, a high-performance cloud database company, who share their insights and experiences. They discuss the motivations for moving analytics to the cloud, the different components that can be migrated, and the alternatives to cloud migration. The experts emphasize the importance of careful planning, involving all relevant teams and stakeholders, and setting clear goals for the migration project. They also discuss the economic factors driving cloud migration, such as cost savings and increased operational efficiency. The experts share success stories and explain how ExaSol's database solution offers high performance and flexibility for analytics tasks. They highlight the need for data governance and the importance of acquiring the necessary skills to effectively use cloud analytics tools. The episode concludes with advice on how to make cloud migration projects successful, including starting with a proof of concept and focusing on quick wins.", "podcast_guest": "Sorry, based on the provided text, it is not possible to determine the name of the guest in the podcast. Could you please provide more specific information or context?", "podcast_highlights": "Some of the highlights of the podcast include:\n\n1. Moving analytics to the cloud allows for flexibility, improved performance, and cost savings.\n2. It's important to start the cloud migration process with a clear understanding of the business needs and objectives.\n3. The various parts of the analytics stack that can be moved to the cloud include the storage layer, integration and ingestion layer, processing layer, and analysis layer.\n4. The decision to move analytics to the cloud depends on factors like flexibility, cost, and security concerns.\n5. Cloud providers have tight security measures in place to protect data.\n6. Economic factors that drive cloud migration include cost savings, scalability, agility, and operational efficiency.\n7. The initial trigger to start the migration process varies from organization to organization and can be driven by issues like performance, cost, or executive mandates.\n8. It's important to involve all stakeholders, including the business, tech teams, and executive decision-makers, in the cloud migration process.\n9. Effective communication and collaboration across teams is crucial for a successful migration project.\n10. Planning and setting clear goals upfront is essential for measuring the success of a cloud migration project.\n11. Some common challenges during the migration process include lack of planning, selecting the right tools for the job, and lack of proper governance.\n12. Exasol's database offers high performance, fast ingestion, and query times, and the ability to handle complex use cases in industries like retail and telecommunications.\n13. Data governance improves with cloud migration due to better metadata management, cataloging, and centralized data repositories.\n14. Cloud migration may require data analysts and data scientists to acquire new skills related to cloud tools and technologies.\n15. Choosing the right tools and infrastructure, knowing their capabilities and limitations, and effectively collaborating with IT teams are important for successful cloud migration.\n16. Starting with a proof of concept and focusing on quick wins while building a long-term strategy is recommended for cloud migration projects.\n17. Organizations should open up their thinking and explore new possibilities and opportunities in the cloud environment.\n18. The podcast guests emphasized the importance of planning, communication, collaboration, and a holistic approach to cloud migration.\n"}